# ğŸ§  AgenticRAG â€”  RAG Assistant 

AgenticRAG is a **Retrieval-Augmented Generation (RAG)** web app built with **Django** and **LangChain**.  
It lets users upload documents (PDF or text), embed them locally using OpenAIâ€™s embedding models, store them in a persistent **ChromaDB**, and query them via a chat-like interface powered by **GPT-4o-mini**.

---

## ğŸš€ Features

- ğŸ“„ Upload and embed **PDF** or **text** files
- ğŸ’¾ Persistent **ChromaDB** vector store
- ğŸ” Context-aware document retrieval (RAG)
- ğŸ’¬ Conversational QA powered by **ChatOpenAI**
- âš™ï¸ Modular design (`loader`, `embeddings`, `vectorstore`, `rag_engine`)
- ğŸ”‘ Secure `.env`-based configuration
- ğŸ§© Fully compatible with **LangChain â‰¥ 0.2** and modern packages (`langchain-core`, `langchain-community`, `langchain-openai`, `langchain-chroma`)

---

## ğŸ§° Tech Stack

| Layer | Technology |
|-------|-------------|
| Backend | Django 5.x |
| LLM / Embeddings | OpenAI API (`gpt-4o-mini`, `text-embedding-3-small`) |
| Retrieval | LangChain + ChromaDB |
| Database | Local persistent Chroma vector DB |
| Language | Python 3.12 |
| Environment | Virtualenv (`rag_env`) |

---

## ğŸ“¦ Installation

### 1. Clone and enter the repo
```bash
git clone https://github.com/<yourusername>/agenticrag.git
cd agenticrag
```
### 2. Create and activate a virtual environment
```bash
python3 -m venv rag_env
source rag_env/bin/activate  # On Windows: rag_env\Scripts\activate
```
### 3. Install dependencies
```
pip install -r requirements.txt

```

### âš™ï¸ Environment Setup

Create a .env file in the same folder as manage.py:
```bash
OPENAI_API_KEY=sk-your-openai-key
OPENAI_MODEL=gpt-4o-mini
CHROMA_DIR=./chroma_db
```

Make sure youâ€™ve added this in manage.py so Django loads it automatically:
```bash
from dotenv import load_dotenv
load_dotenv()
```


### ğŸ—ï¸ Project Structure
```bash
agenticrag/
â”œâ”€â”€ manage.py
â”œâ”€â”€ .env
â”œâ”€â”€ ragcore/
â”‚   â”œâ”€â”€ views.py
â”‚   â”œâ”€â”€ urls.py
â”‚   â””â”€â”€ rag/
â”‚       â”œâ”€â”€ loader.py
â”‚       â”œâ”€â”€ embeddings.py
â”‚       â”œâ”€â”€ vectorstore.py
â”‚       â””â”€â”€ rag_engine.py
â””â”€â”€ chroma_db/  â† persisted vector database
```
### Key modules
```bash
File	Purpose
loader.py	Loads .pdf or .txt into LangChain Documents
embeddings.py	Wraps OpenAIEmbeddings with key from .env
vectorstore.py	Creates persistent Chroma vector DB
rag_engine.py	Runs the retrieval + LLM chain (RAG)
views.py	Django routes for /upload/ and /ask/ endpoints
```

### â–¶ï¸ Running the Server
```bash
python manage.py runserver
```
Visit http://localhost:8000ï¿¼
You can:
	â€¢	Upload PDFs or text files at /upload/
	â€¢	Ask questions at /ask/
